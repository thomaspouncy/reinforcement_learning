{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.51948839  8.72359135  4.54626916  5.65477528  1.69756493]\n",
      " [ 1.97471567  3.14150346  2.39211602  2.11921125  0.7170501 ]\n",
      " [ 0.25191769  0.87181455  0.82464287  0.65477528 -0.23582585]\n",
      " [-0.86770262 -0.34333271 -0.25362642 -0.45269118 -1.07300331]\n",
      " [-1.78622733 -1.27640865 -1.15584751 -1.34010637 -1.89627214]]\n"
     ]
    }
   ],
   "source": [
    "#exact solution\n",
    "a = np.reshape([-2.2,0.9,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0.9,-3.1,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,-1,0,0,0,0,0,0,0,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,-2.2,0,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0,-3.1,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-3.1,0,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0,-3.1,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-3.1,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-3.1,0,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0,-3.1,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-4,0.9,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-3.1,0,0,0,0,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0,-2.2,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-3.1,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-3.1,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-3.1,0.9,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0.9,0,0,0,0.9,-2.2],(25,25))\n",
    "# print a\n",
    "b = np.reshape([2,-10,1,-5,2,1,0,0,0,1,1,0,0,0,1,1,0,0,0,1,2,1,1,1,2],(25,1))\n",
    "# print b\n",
    "res = np.linalg.solve(a,b)\n",
    "print np.reshape(res,(5,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#policy evaluation approximation:\n",
    "\n",
    "#functions\n",
    "def transition(state,action,new_state):\n",
    "    if state == 1:\n",
    "        if new_state == 1:\n",
    "            return 1.0\n",
    "    elif state == 16:\n",
    "        if new_state == 16:\n",
    "            return 1.0\n",
    "    elif action == 'n':\n",
    "        if state in [2,3,4]:\n",
    "            if new_state == state:\n",
    "                return 1.0\n",
    "        else:\n",
    "            if new_state == state-4:\n",
    "                return 1.0\n",
    "    elif action == 'w': \n",
    "        if state in [5,9,13]:\n",
    "            if state == new_state:\n",
    "                return 1.0\n",
    "        else:\n",
    "            if new_state == state - 1:\n",
    "                return 1.0\n",
    "    elif action == 'e':\n",
    "        if state in [4,8,12]:\n",
    "            if new_state == state:\n",
    "                return 1.0\n",
    "        else:\n",
    "            if new_state == state + 1:\n",
    "                return 1.0\n",
    "    elif action == 's':\n",
    "        if state in [13,14,15]:\n",
    "            if new_state == state:\n",
    "                return 1.0\n",
    "        else:\n",
    "            if new_state == state + 4:\n",
    "                return 1.0\n",
    "    \n",
    "    return 0.0\n",
    "\n",
    "def reward(state,action,new_state):\n",
    "    if state == 1 or state == 16:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return -1.0\n",
    "        \n",
    "y = 0.9\n",
    "states = [x+1 for x in range(16)]\n",
    "policy = [{'n': 0.25, 'e': 0.25, 's': 0.25, 'w': 0.25} for x in range(16)]\n",
    "actions = ['n','e','s','w']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0.75786328125\n",
      "0\n",
      "1.539\n",
      "0.0644116383957\n",
      "0.014492618639\n",
      "0.00326083919378\n",
      "0.000733688818601\n",
      "0.000165079984185\n",
      "3.71429964412e-05\n",
      "8.35717419978e-06\n",
      "1.88036419502e-06\n",
      "4.23081943701e-07\n",
      "9.51934371329e-08\n",
      "[[ 0.         -1.         -1.9        -2.71      ]\n",
      " [-1.         -1.9        -2.71       -3.439     ]\n",
      " [-1.9        -2.71       -1.9        -2.84035487]\n",
      " [-2.71       -1.9        -1.          0.        ]]\n",
      "[['s' 'w' 'w' 'w']\n",
      " ['n' 'w' 'n' 'n']\n",
      " ['n' 'w' 's' 's']\n",
      " ['n' 'e' 'e' 's']]\n"
     ]
    }
   ],
   "source": [
    "vals = list(np.zeros(16))\n",
    "while True:\n",
    "    # policy evaluation\n",
    "    thresh = 0.0000001\n",
    "    while True:\n",
    "        delta = 0\n",
    "\n",
    "        for state in states:\n",
    "            new_val = 0\n",
    "            for action in actions:\n",
    "                for new_state in states:\n",
    "                    new_val +=  policy[state-1][action] * transition(state,action,new_state) * (reward(state,action,new_state) + y * vals[new_state-1])\n",
    "            delta = max([delta,(new_val - vals[state-1])])\n",
    "            vals[state-1] = new_val\n",
    "\n",
    "        print delta\n",
    "        if delta < thresh:\n",
    "            break;\n",
    "    \n",
    "    # policy improvement\n",
    "    policy_stable = True\n",
    "    for s in states:\n",
    "        temp = max(policy[s-1].keys(), key=(lambda k: policy[s-1][k]))\n",
    "        temp_vals = {'n': 0.0,'e': 0.0,'s': 0.0,'w': 0.0}\n",
    "        old_val = 0\n",
    "        for action in actions:\n",
    "            for new_state in states:\n",
    "                temp_vals[action] += transition(s,action,new_state) * (reward(s,action,new_state) + y * vals[new_state-1])\n",
    "            if action == temp:\n",
    "                old_val = temp_vals[action]\n",
    "        new = max(temp_vals.keys(), key=(lambda k: temp_vals[k]))\n",
    "        new_val = max(temp_vals.values())\n",
    "        \n",
    "        if new != temp and new_val > old_val:\n",
    "            policy_stable = False\n",
    "            policy[s-1] = {'n': 0.0,'e': 0.0,'s': 0.0,'w': 0.0}\n",
    "            policy[s-1][new] = 1.0\n",
    "    \n",
    "    if policy_stable:\n",
    "        break\n",
    "    \n",
    "print np.reshape(vals,(4,4))\n",
    "opt_pol = [max(p.keys(), key=(lambda k: p[k])) for p in policy]\n",
    "print np.reshape(opt_pol,(4,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'a':1,'b':2}.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
